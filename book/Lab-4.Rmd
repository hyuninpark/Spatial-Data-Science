# Lab 4. Principles of Spatial Scale, Part 2

## Overview

In this practical, we will continue to explore how coal mining impacts West Virginia in a contemporary context. Extending from our work last week exploring county-level variations, this week's objectives will be to:

- learn some basics of R 
- wrangle Census data
- access data through the Web
- compare data between sources & scales

## Research Question
We have been focusing on coal mining jobs at the county-scale. This is partly due to a data limitation, as we know the exact number of jobs for coal-mining at the county level. However, is the scale of coal-mining at the county level, or below? Will there be more variation at a smaller area of resolution? Are jobs equally distributed throughout the county, or will they tend to clump in certain areas within a county -- and if so, why would that be the case? 

In other words: Is coal mining spatially homogeneous throughout the state, or throughout different counties -- or is it spatially heterogeneous, with “clumping” behaviors? If there is a spatially heterogeneous pattern, what may tie coal mining jobs to a certain place? Is there a pattern of spatial dependence? 

## Environment Setup

For this lab, you'll need to have R and RStudio downloaded and installed on your system. You should be able to install packages, and have very basic familiarity with R following [intro-level tutorials](https://learn.datacamp.com/courses/free-introduction-to-r) provided through [installation guides](https://rspatial.org/intr/1-introduction.html). You should also know how to find the address to a folder on your computer system.  

We will work with the following libraries, so please be sure to install:

- sf 
- tmap
- RColorBrewer
- tidyverse
- tidycensus

Coding snippets from https://walkerke.github.io/ and [https://data.cdrc.ac.uk](https://data.cdrc.ac.uk/tutorial/an-introduction-to-spatial-data-analysis-and-visualisation-in-r) were used in the development of this lab practical.

## Need for finer data
In order to examine this further, we need to look at data at a smaller areal resolution. While we don’t have an exact number of coal mining jobs below county, the American Community Survey (ACS) does provide an approximation of mining grouped within an industry variable at the census-tract level. Census tracts are smaller units used by the Census to track populations, and encompass a population between 2,500 to 8,000 people. When using tract-level files from the ACS, it is recommended to only use 5-year estimates because of the large margins of error in smaller year samples. 

## Census Data
The mining data we used last week indicated *exact* counts of employees working within the coal mining industry at the county level, by year. If we wanted to find similar data using the Census, the closest variable available would be Mining jobs as part of the industry category “Agriculture, forestry, fishing and hunting, and mining” at the county or tract level within the American Community Survey (ACS 5-year estimate). Before we explore this data at the tract level, let's first compare the county-level data between sources: Bureau of Labor Statistics (BLS) and ACS. 

We will first work with ACS data provided as a `CSV` file format, to be joined to the master West Virginia county `shapefile` we generated last week. 

### Working Directory Setup
To do this, we first need to ensure we have a working directory where your code and data reside. Make sure that your R script, CSV file provided, and WV county shapefile are all in the same folder. Identify the address to this folder.

Now we can set up our working directory. Again, this will be the folder on your computer system where you are storing script and data for this lab. Ensure that you are working from the script from this folder.

```{r}
# Set working directory
#setwd("/Users/maryniakolak/Desktop/WVCoal")
```

### Load Libraries
Before loading our data, we will need to load the required packages. While we can load a CSV using base R capabilities, we need the `sf` package to load spatial data.

If you have not installed `sf`, do so now. You can uncomment the line of code to install, but then re-comment it so you don't install the package more than once. We also load the `tidyverse` package to enable some useful data wrangling tools.

```{r}
# install.packages("sf")
library(sf)
library(tidyverse)
```

### Load Data

Next, load the census data and read in the shapefile of your counties file. While it reads in as a shapefile, the data structure gets changed to a "simple features" dataset that inludes geometry as an additional column. This is a key feature of the `sf` package.
```{r}
# Load new census data you plan to join.
Census.Data <-read.csv("ACS_15_5YR_DP03.csv")

# Load the output area shapefiles
County.Areas<- st_read("WV_Counties.shp")
```

### View Data

We can quickly view the attributes. One way is to use the `glimpse` function. Uncomment this line in your script, and view the data.

```{r}
# View the attributes associated with each county
glimpse(County.Areas)
```

We can also use the `head()` function, which shows the top 5 rows. Uncomment this in your script, and view the data.
```{r}
# View the attributes associated with each county
# head(Census.Data)
```

If we want to see the dimensions of the data, we can use the `dim()` function. I also like the `str()` function as it gives an overview of what type of data we have from a data structure perspective. I comment out the `str()` function here as it generates a very long output, but please try for yourself!

From either of these we can see that there 55 observations (counties), and 551 variables. In other words, 55 rows x 551 columns.
```{r}
# View the attributes associated with each county
dim(Census.Data)
#str(Census.Data)
```

### Subset Data
This ACS dataset -- a raw file from the *DP03: Selected Economic Characteristics* summary profile  -- includes a lot of variables. To work with this we need to know exactly what variabes we need. You would need the metadata document that comes with the summary profile to identify that. In this lab, I will tell you which variables we're interested in.

- HC03_VC50: Percent; INDUSTRY - Civilian employed population 16 years and over - Agriculture, forestry, fishing and hunting, and mining

- HC01_VC85: Estimate; INCOME AND BENEFITS (IN 2010 INFLATION- ADJUSTED DOLLARS) - Median household income (dollars). 

In other words, we need to generate a subset of the raw ACS file to include the unique numerical County geographic ID, and rename the variables of interest.

- County ID   -> named "GEO.id2" in dataset
- HC03_VC50   -> rename “AgFHM15”
- HC01_VC85   -> rename “MedInc15”

Let's further subset the data to make a new, cleaner dataset. We first generate a list of variables that we want to keep. Note that "GEO.id2" is the unique code that indicates a county. We will use this as our "key" to merge with our master spatial file.

```{r}
var <- c("GEO.id2","HC01_VC85","HC03_VC50")
```

Next, we extract only the variables of interest from the ACS dataset. We call this new object "Census.Subset." View the data to ensure you've subset correctly.

Also note that there are multiple ways to subset data in R -- here we use a simple base R approach. The `tidyverse` package offers even more elegant options.

```{r}
Census.Subset<- (Census.Data[var])
glimpse(Census.Subset)
```

Next, we rename the second and third columns (identified as 2 through 3) using new names. Again, there are many ways to do this in R -- this is just one approach.
```{r}
names(Census.Subset)[2:3]<- c("MedInc15", "AgMnJb15")
glimpse(Census.Subset)
```

## Merge data to Master
Now that you've cleaned and named the census data showing our mining proxies, we can merge to our Master spatial file.

Note that we are joining using key "FIPSSTCO" from the county shapefile, and "GEO.id2" from the census dataset. Look at the data to make sure it joined correctly.


```{r}
# Joins data to the shapefile
WV_county <- merge(County.Areas, Census.Subset, by.x="FIPSSTCO", by.y="GEO.id2")
head(WV_county)
```
Great! 

## Mapping in R 
There are multiple libraries that exist for mapping in R. We will use `tmap` and to a lesser extent,`ggplot` in this lab. Let's start with `tmap.` 

First, we need to add the libraries. Install the libraries if you have not done so.

### Load packages 
```{r}
library(tmap)
library(RColorBrewer)
```

### View palette options
It is helpful to have a nice range of color palette options when mapping in R. Load the `RColorBrewer` library and display all the options available to you. Each palette option has a name attached -- the is the name that you indicate as a parameter for mapping in `tmap.` 

While this appears "squished" when rendered via RMarkdown, you can expand the view when run via your Console or via R script. 

```{r}
# Display the color palette
display.brewer.all()
```

### Basic tmap functions
For basic mapping in R using `tmap`, you have two functions for each variable you need to map. Obviously the data needs to be the spatial file you've generated and loaded into the environment. Our Master spatial file is named "WV_county" in our setting here. To visualize the "AgMnJb15" variable (our ACS mining proxy) we add this to the `tm_fill` parameter. This generates a default choropleth map.

```{r}
# Creates a simple choropleth map of our a AgMnJb15 variable
tm_shape(WV_county) + tm_fill("AgMnJb15") 
```
While this is not a perfect proxy for mining jobs, some of the patterns are consistent with the BLS data source. We can see that majority of jobs in this dataset are in the Southern part of West Viriginia, in the same area as the highest proportions of coal mining jobs. What areas are less well represented? Why may that be the case?

### Set color palette
With ColorBrewer, we can switch palettes. If you would like to change the direction of the palette, just add a "negative" sign.

```{r}
# setting a color palette
tm_shape(WV_county) + tm_fill("AgMnJb15", palette = "-BrBG") 
```

### Classify data 
You can also change the data classification interval. It defaults on a "pretty classification" which has been optimized for easy-to-read breaks, but may not best reflect the actual data distribution To see different parameter options, research the `tmap` documentation page.

Here we try quantile breaks, and then specific the number of levels or breaks.

```{r}
# changing the intervals 
tm_shape(WV_county) + tm_fill("AgMnJb15", style = "quantile", palette = "-BrBG")

# number of levels
tm_shape(WV_county) + tm_fill("AgMnJb15", style = "quantile", n = 7, palette = "-BrBG")
```

How does this change your interpretation? Try additional parameter specifications like "jenks" for jenks breaks, or "sd" for standard deviation breaks.

### Customize Maps

There are multiple other options when designing maps using `tmap.` Many of these are best optimized for generating in an R script directly, rather than in an RMarkdown, as RStudio can enforce odd behaviors when it doesn't have full space to generate plots. Take the following code as examples for what you should try in your own RStudio environment within an R script (rather than an RMarkdown file).

Finally, experiment with the parameters here, and continue to explore the tmap documentation. (Google search terms: "tmap R" to get information directly.) 

```{r}
# includes a histogram in the legend
tm_shape(WV_county) + tm_fill("AgMnJb15", style = "jenks", n=6, palette = "-BrBG", legend.hist = TRUE) 

# add borders
tm_shape(WV_county) + tm_fill("AgMnJb15", style = "jenks", n=6, palette = "-BrBG") + 
  tm_borders(alpha=.4)

# north arrow
tm_shape(WV_county) + tm_fill("AgMnJb15", style = "jenks", n=6, palette = "-BrBG") + 
  tm_borders(alpha=.4) +
  tm_compass()

# adds in layout, gets rid of frame
tm_shape(WV_county) + tm_fill("AgMnJb15", palette = "-BrBG", style = "jenks", title = "% Jobs High Risk Employment") + 
  tm_borders(alpha=.4) + 
  tm_compass() + 
  tm_layout(legend.text.size = 1.1, legend.title.size = 1.5, legend.position = c("right", "bottom"), frame = FALSE) 
```

### Facet mapping

Now that we have a Master spatial dataset that includes both mining job proxies, we can compare them. How close is the mining proxy data from the ACS profile to the actual mining employment numbers from BLS? To do this we generate a "facet map" meaning we show multiple maps, side by side.

We first assign each map to a variable, and then use either `tmap_arrange` or `tm_facets` to generate our facet maps.

```{r}
# ReMap
BLSData <- tm_shape(WV_county) + tm_fill("AveEmp15", palette = "BuPu", style = "jenks", title = "Coal Mng Jobs") + 
  tm_borders(alpha=.4) + 
  tm_layout(legend.text.size = .8, legend.title.size = 1.0, legend.position = c("right", "bottom"), frame = FALSE) 

ACSData <- tm_shape(WV_county) + tm_fill("AgMnJb15", palette = "BuPu", style = "jenks", title = "High Risk Job %") + 
  tm_borders(alpha=.4) + 
  tm_layout(legend.text.size = .8, legend.title.size = 1.0, legend.position = c("right", "bottom"), frame = FALSE) 

tmap_arrange(BLSData,ACSData)
```

Here's another way to generate the maps side by side:

```{r}
# Another Route:
tm_shape(WV_county) +
  tm_polygons(c("AveEmp15", "AgMnJb15"), 
              style=c("jenks", "jenks"),
              palette=list("BuPu", "BuPu"),
              title=c("Coal Mng Jobs", "High Risk Jobs %")) +
  tm_facets(ncol=2) 
```

Obviously the ACS data is overestimating in some areas, and undestimating in others. While it captures the increase in mining jobs in the Southermost area, it misses the county with the highest mining jobs when considering all the other employment categories included. Getting finer resolution data for coal mining below county may not be available, but at least we know relatively how useful this Census category is. 

## Using a Census API
In this lab I  provided the raw data to you for 2015 that you wrangled and cleaned. Another excellent option in R coding environments is using a package to extract Census data for you. While you won't be able to access all the data the same way, for some of the "classic" indicators like population demographics and income, using the Census API is the most efficient approach.

Let's extract median income for WV counties and census tracts to see if we gain any insight into our analysis.

### Workspace Setup
Examples in this section were sourced from Kyle Walker's guide to using tidycensus: [Basic Usage of tidycensus](https://walkerke.github.io/tidycensus/articles/basic-usage.html) and [Spatial Data in tidycensus](https://walkerke.github.io/tidycensus/articles/spatial-data.html). If you run into challengs, feel free to peruse the original context for more ideas. 

### Load libraries

```{r}
library(tidyverse)
library(tidycensus)
options(tigris_use_cache = TRUE)
```

### Activate your API key
To work with tidycensus, you must first register for and activate your Census API key. A key can be obtained from http://api.census.gov/data/key_signup.html. Register and activate your API key.

Next, add your API key to your RStudio coding environment. This should be done in your console or your personal file; the API key should not be shared. I include dummy code below that has been commented out. For my implementation to work, I needed to add two additional parameters after simple debugging.

```{r}
#census_api_key("YOURAPIKEY", install=TRUE, overwrite = TRUE)
```

Using the documentation for tidycensus by Kyle Walker, we first load variables from the ACS 5-year estimated for 2015 (so from years 2011-2015). The "view" option opens a window in your RStudio environment where you can explore the Census variables available to you in detail. This is how you can find the definitions of the variables of interest, using the search functionality availble in RStudio. See the Kyle Walker demo for more specifics.

The `view(ACS15var)` call is a critical component to using tidycensus. This lets you explore all the available options to you when extracting variables, serving as a metadata file. Use the "search" function in RStudio to explore this dataset after it opens. Try searching for "income" for example -- how many options are available to you? Uncomment and explore!

```{r}
ACS15var <- load_variables(2015, "acs5", cache = TRUE)
#view(ACS15var)

```

### Extract Census data
Next we can extract the exact data. This functions gathers data for median income levels for all counties in West Virginia, using the 2015 dataset. 

*Note:* this call can take some time to pull. It's not necessary to go through for the lab, so it's okay to skip if you are running into issues.

### Access census estimates
```{r}
WV_county_medinc <- get_acs(geography = "county", 
              variables = c(medincome = "B19013_001"), 
              state = "WV", 
              year = 2015)

WV_county_medinc
```

### Access merged spatial file
The latest edition of `tidycensus` adds the ability to extract census attribute data with the spatial data already merged. The object is thus a spatial file, not a simple data file.

```{r}


WV_county_medinc.sp <- get_acs(state = "WV", 
                     geography = "county", 
                     variables = "B19013_001", 
                     geometry = TRUE)

head(WV_county_medinc.sp)
```

### Plot data
Using Walker's `tidycensus` vignette, you can quickly plot the data using `ggplot`. We didn't need to install `ggplot` because it was part of the `tidyverse` library. 
```{r}
WV_county_medinc.sp %>%
  ggplot(aes(fill = estimate)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c(option = "magma") 
```

Of course, you can also plot using `tmap.` Note that the variable of interest is called "estimate" here, using the `tidycensus` default. I recommend just working with one attribute at a time when first working with `tidycensus` and R.

```{r}
tm_shape(WV_county_medinc.sp) + tm_fill("estimate", palette = "BuPu", title ="Median Income")
```

### Rinse and Repeat
What's nice about `tidycensus` is that we can quickly run the same function to get the spatial data at a different resolution. Here we can gather median income information at the tract level.

```{r}
WV_tracts_medinc.sp <- get_acs(state = "WV", 
                     geography = "tract", 
                     variables = "B19013_001", 
                     geometry = TRUE)

head(WV_tracts_medinc.sp)
```

Next, we can plot it using both `ggplot` and `tmap.` 


```{r}
WV_tracts_medinc.sp %>%
  ggplot(aes(fill = estimate)) + 
  geom_sf(color = NA) + 
  scale_fill_viridis_c(option = "magma") 
```


```{r}
tm_shape(WV_tracts_medinc.sp) + tm_fill("estimate", style = "jenks", palette = "BuPu", title ="Median Income")
```

What new insights did you find? 

## Scale of Coal Mining

Finally -- so, what about the scale of coal mining in West Virginia? While we know the ACS data is an imperfect represetnation of coal mining the state, we also know it captures some of the higher proportions of mining employment, especially in the Southern part of the state.

After exploring the "view" of the ACS data pulled, the closest variable I could find was B24031_002 - or the "Estimate of total persons in Agriculture, forestry, fishing and hunting, and mining." The ACS profile used in `tidycensus` does not link directly to the specific report we need to match our analysis exactly, but this should capture some of the same variation.

Thus, let's map this variable at County and Tract scales to look for some patterns.

### Extract Data
First, we extract the data:
```{r}
WV_county_mining.sp <- get_acs(state = "WV", 
                     geography = "county", 
                     variables = "B24031_002", 
                     geometry = TRUE)

WV_tracts_mining.sp <- get_acs(state = "WV", 
                     geography = "tract", 
                     variables = "B24031_002", 
                     geometry = TRUE)

```

### Map Data
Next, we map both side by side: 

```{r}
# ReMap
WVCounties <- tm_shape(WV_county_mining.sp) + tm_fill("estimate", n=4, palette = "BuPu", style = "jenks", title = "High Risk Jobs") + 
  tm_borders(alpha=.4) + 
  tm_layout(legend.text.size = .8, legend.title.size = 1.0, legend.position = c("right", "bottom"), frame = FALSE) 

WVTracts <- tm_shape(WV_tracts_mining.sp) + tm_fill("estimate", n=4, palette = "BuPu", style = "jenks", title = "High Risk Jobs") + 
  tm_borders(alpha=.4) + 
  tm_layout(legend.text.size = .8, legend.title.size = 1.0, legend.position = c("right", "bottom"), frame = FALSE) 

tmap_arrange(WVCounties,WVTracts)
```

## Interpretation
What type of variation do you find between these maps? Knowing that there is more connection with mining in th Southern area, were you suprised by the variation below the county level? At what scale is coal mining employment occurring? Broadening to a wider "High Risk Employment" category for jobs that are more prone to accidents (including construction, mining, agricultural, etc) captured in this Census variable, what additional insights might you have? 

Note that this variable is sometimes used for identifying areas at risk for opioid overdose. If some jobs are more prone to injury, then workers could also be more prone to getting prescription opioids for pain management, a component of the opioid epidemic. At the same time, these areas often have few other job options. When high-paying coal mining jobs go away ("high" relative to median income in the area), there may not be other options that promise the same pay and/or stability. This "economics of despair" concept likewise is thought the drive increases in opioid-related overdoses. Consider the complexity here -- and how might you further detangle these concepts?   

## Appendix

### Write to CSV
After all the hard work in this analysis, you'll want to save the master files you generated. One option is to save the attribute component of the data you generated, using a `CSV` file. Uncomment and run on your own.

```{r}
# write.csv(WV_county, "WV_county.csv")
```

### Write to SHP
The `st_write` function saves the spatial file as a `shapefile.` For example you can save the county file you updated earlier. Uncomment and run on your own. The file is save to your working directory.

```{r}
# st_write(WV_county, "WV_county.shp")
```

### Census Data Access
While the `tidycensus` package is great for straightforward variables like income level, it may not always be for all variables. For example, if we search for "mining" in the existing View only a small selection is returned. We could for example try variable "B08126_002" corresponding to the total estimate of persons in Agriculture, forestry, fishing and hunting, and mining industries, but this is not the percentage of the workforce in these industries (which would be more precise). Rather than calculate this on our own (which also needs to account for the total able-to-work population), it's more efficient to use pre-calculated Census metrics. 

I thus recommend that for more detailed Census explorations, you take the time to get familiar with various Census data profiles.

For your own research, I recommend investigating [IPUMS](https://ipums.org/) and the newly revised [Data.gov](https://www.data.gov/) site that releases more detailed Census profiles with ther required metadata components. The previous version, American Factfinder, has been retired.


